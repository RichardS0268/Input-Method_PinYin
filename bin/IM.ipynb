{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path\n",
    "hanzi_table = \"../src/一二级汉字表.txt\"\n",
    "yuliao_data = \"../src/sentences_normal.txt\" # 预处理后的语料库路径\n",
    "pinyin_table = \"../src/拼音汉字表.txt\"\n",
    "transfer_matrix_path = \"../src/MPDH/0_data/0_all.csv\"\n",
    "emit_marix_path = \"../src/MPDH/1_data/1_all.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 制作拼音表, 格式：{'a': ['啊', '嗄', '腌', '吖', '阿', '锕'], ... }\n",
    "pinyin_biao2 = {}\n",
    "with open(pinyin_table, \"r\", encoding = 'utf-8') as f_read:\n",
    "    lines = f_read.readlines()\n",
    "    for line in lines:\n",
    "        line = line.split()\n",
    "        pinyin_biao2[line[0]] = line[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 制作拼音表，所有合法的输入\n",
    "pinyin_biao = []\n",
    "with open(hanzi_table, \"r\", encoding=\"utf-8\") as f1:\n",
    "    with open(pinyin_table, \"r\", encoding=\"utf-8\") as f_read:\n",
    "        data = f1.read()\n",
    "        lines = f_read.readlines()\n",
    "        for i in range(len(lines)):\n",
    "            line = lines[i].split()\n",
    "            pinyin_biao.append(line[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(hanzi_table, \"r\", encoding=\"utf-8\") as f1:\n",
    "    hanzi_set = f1.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义HMM model\n",
    "class HMM:\n",
    "    def __init__(self, mid = \"01\", ir = 0.5, hanzi_num=6763):\n",
    "        self.MID = mid # 模型标号，如果是load已有模型的话，MID变为已有模型的编号\n",
    "        self.hanzi_map = {} # 对所有汉字建立索引\n",
    "        self.duyin_map = {} # 对所有拼音建立索引\n",
    "        self.hanzi_num = hanzi_num\n",
    "        self.ir = ir\n",
    "\n",
    "    def cal_init_map(self): # 构建hanzi_map和duyin_map\n",
    "        '''\n",
    "        - 计算每个汉字在语料库在中出现的次数，作为初始化矩阵Pi\n",
    "        '''\n",
    "        print(\"Constructing MAP ...\")\n",
    "\n",
    "        with open(hanzi_table, 'r', encoding='utf-8') as f_read1:\n",
    "            data1 = f_read1.read()\n",
    "            for i in range(len(data1)):\n",
    "                self.hanzi_map[i] = data1[i]\n",
    "            \n",
    "        with open(pinyin_table, \"r\", encoding=\"utf-8\") as f_read2:\n",
    "            lines = f_read2.readlines()\n",
    "            for i in range(len(lines)):\n",
    "                line = lines[i].split()\n",
    "                self.duyin_map[i] = line[0]\n",
    "\n",
    "    def cal_transfer_matrix(self):\n",
    "        '''\n",
    "        - 计算转移矩阵\n",
    "        '''\n",
    "        print(\"Constructing Transfer-matrix ...\")\n",
    "        self.transfer = pd.read_csv(transfer_matrix_path)\n",
    "    \n",
    "    def cal_emit_matrix(self):\n",
    "        '''\n",
    "        - 计算发射矩阵\n",
    "        - 调用外部 API (pypinyin: https://pypi.org/project/pypinyin/ )，转换语料库的拼音，不能直接认为每个字的每个读音都是平均的\n",
    "        '''\n",
    "        print(\"Constructing Emit-matrix ...\")\n",
    "        self.emit_matrix = pd.read_csv(emit_marix_path)\n",
    "        self.emit_matrix = self.emit_matrix.fillna(0)\n",
    "\n",
    "    \n",
    "    def train(self):\n",
    "        print(\"Model Training ...\")\n",
    "        self.train_file = [hanzi_table, yuliao_data]\n",
    "        self.cal_init_map()\n",
    "        self.cal_transfer_matrix()\n",
    "        self.cal_emit_matrix()\n",
    "        print(\"Training Process Finished\")\n",
    "\n",
    "    def decoding(self, Input):\n",
    "        '''\n",
    "        - input结构为数组\n",
    "        - 维特比算法，进行decoding，实现全拼输入法功能\n",
    "        '''\n",
    "        delta = []\n",
    "        h_words = []\n",
    "        sentence = []\n",
    "        for i in range(len(Input)):\n",
    "            spelling = Input[i]\n",
    "            emit_prob = []\n",
    "            if (i == 0): # 第一个拼音\n",
    "                h_words = [hanzi_set.find(x) for x in pinyin_biao2[spelling]] # 隐变量(汉字的rank)集合\n",
    "                sentence = [self.hanzi_map[y] for y in h_words] # 隐变量(汉字)集合\n",
    "                emit_prob = [self.emit_matrix.iloc[list(self.duyin_map.values()).index(spelling), x] for x in h_words] # 该拼音对应的各汉字的概率\n",
    "                head_prob = [self.transfer.iloc[x, -1] for x in h_words] # 各汉字出现句首的概率\n",
    "                delta = np.multiply(np.power(np.array(emit_prob), self.ir),np.power(np.array(head_prob), 1-self.ir)).tolist()\n",
    "                # 归一化处理\n",
    "                delta_sum = sum(delta)\n",
    "                delta = [d / delta_sum for d in delta]\n",
    "\n",
    "                \n",
    "            else:\n",
    "                temp_h_words = [hanzi_set.find(x) for x in pinyin_biao2[spelling]] # 隐变量(汉字的rank)集合\n",
    "                emit_set = [self.emit_matrix.iloc[list(self.duyin_map.values()).index(spelling), x] for x in temp_h_words] # 该拼音对应的各汉字的概率\n",
    "                temp_sentence = []\n",
    "                temp_delta = []\n",
    "                for word in temp_h_words: # 对于所有可能的隐变量\n",
    "                    # 分别计算转移概率和发射概率，将乘积最大的作为这一组隐变量的delta\n",
    "                    trans_prob = [self.transfer.iloc[word][x]*delta[h_words.index(x)] for x in h_words] # 计算上一个状态的变量到达这个变量的转移概率\n",
    "                    temp_delta.append(max(trans_prob)*emit_set[pinyin_biao2[spelling].index(hanzi_set[word])])\n",
    "                    temp_sentence.append(sentence[trans_prob.index(max(trans_prob))] + self.hanzi_map[word])\n",
    "                \n",
    "                # 归一化处理\n",
    "                delta_sum = sum(temp_delta)\n",
    "                delta = [x/delta_sum for x in temp_delta]\n",
    "                sentence = temp_sentence\n",
    "                h_words = temp_h_words\n",
    "\n",
    "        output = sentence[delta.index(max(delta))]\n",
    "        print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training ...\n",
      "Constructing MAP ...\n",
      "Constructing Transfer-matrix ...\n",
      "Constructing Emit-matrix ...\n",
      "Training Process Finished\n"
     ]
    }
   ],
   "source": [
    "pinyin3 = HMM()\n",
    "pinyin3.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_shell(engine):\n",
    "    '''\n",
    "    engine是翻译引擎，HMM对象\n",
    "    '''\n",
    "    print(\"using engine::\"+ engine.MID + \" --initial rate = \" + str(engine.ir))\n",
    "    print(\"输入\\\"exit\\\"退出程序\")\n",
    "    while True:\n",
    "        data = input(\"输入全拼:\")\n",
    "        if (data == \"exit\"):\n",
    "            print(\"--EXIT--\")\n",
    "            break\n",
    "        else:\n",
    "            try:\n",
    "                # 先判断是否有非法输入\n",
    "                quanpin = data.split()\n",
    "                valid_input = 1\n",
    "                illegal = \"\"\n",
    "                for yin in quanpin:\n",
    "                    if yin not in pinyin_biao:\n",
    "                        valid_input = 0\n",
    "                        illegal += \" \" + yin\n",
    "                if not valid_input:\n",
    "                    print(\"含有非法输入: \" + illegal)\n",
    "                else:\n",
    "                    engine.decoding(quanpin)\n",
    "            except:\n",
    "                print(\"Error\")\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using engine::01 --initial rate = 0.5\n",
      "输入\"exit\"退出程序\n",
      "清华大学计算机系\n",
      "--EXIT--\n"
     ]
    }
   ],
   "source": [
    "convert_shell(pinyin3)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c65d005f803e204758a0832aa4706f4cea84163cd45d2efe412da3167c3b3a79"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('tf2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
