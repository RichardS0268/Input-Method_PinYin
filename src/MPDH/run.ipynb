{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path\n",
    "hanzi_table = \"../一二级汉字表.txt\"\n",
    "pinyin_table = \"../拼音汉字表.txt\"\n",
    "yuliao_data = \"../sentences_normal.txt\" # 预处理后的语料库路径\n",
    "pinyin_data = \"../pinyin_normal.txt\"\n",
    "process0_path = \"./0_Process/\"\n",
    "data0_path = \"./0_data/\"\n",
    "process1_path = \"./1_Process/\"\n",
    "data1_path = \"./1_data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hanzi_map = {}\n",
    "duyin_map = {}\n",
    "\n",
    "with open(hanzi_table, 'r', encoding='utf-8') as f_read1:\n",
    "    data1 = f_read1.read()\n",
    "    for i in range(len(data1)):\n",
    "        hanzi_map[i] = data1[i]\n",
    "    \n",
    "with open(pinyin_table, \"r\", encoding=\"utf-8\") as f_read2:\n",
    "    lines = f_read2.readlines()\n",
    "    for i in range(len(lines)):\n",
    "        line = lines[i].split()\n",
    "        duyin_map[i] = line[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0_Process: 计算transition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 根据模板文件，多进程操作\n",
    "with open(process0_path + \"00_template.txt\") as f:\n",
    "    template = f.read()\n",
    "for i in range(46):\n",
    "    with open(process0_path + f\"0_Process{i}.txt\", \"w\") as f:\n",
    "        rank = i\n",
    "        file = re.sub(\"X_NUM_X\", str(i), template)\n",
    "        f.write(file)\n",
    "    \n",
    "with open(process0_path + \"0_run.txt\", \"w\") as ff:\n",
    "    for i in range(46):\n",
    "        ff.write(\"nohup python \" + process0_path+ f\"0_Process{i}.txt >> \" + process0_path + f\"log/P{i}.log 2>&1 &\" + '\\n')\n",
    "\n",
    "os.system(\"sh \" + process0_path + \"0_run.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看日志文件，当csv文件全部生成后执行下一步"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "filelist  = listdir(data0_path)\n",
    "print(len(filelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并各进程结果\n",
    "while True:\n",
    "    filelist  = listdir(data0_path)\n",
    "    if len(filelist) == 46:\n",
    "        dff = pd.read_csv(data0_path + \"Process::0.csv\")\n",
    "        for i in tqdm(range(1, 46), desc=\"reading\"):\n",
    "            dff2 = pd.read_csv(data0_path+ f\"Process::{i}.csv\")\n",
    "            dff = dff + dff2\n",
    "        head_sum = sum(list(dff.iloc[:, -1]))\n",
    "        dff.iloc[:, -1] = dff.iloc[:, -1]/head_sum\n",
    "        for i in tqdm(range(6763), desc=\"merging\"):\n",
    "            row_sum = sum(dff.iloc[i, :-1])\n",
    "            dff.iloc[i, :-1] = dff.iloc[i, :-1]/row_sum\n",
    "        dff.to_csv(data0_path+ \"0_all.csv\", index=0)\n",
    "        os.system(\"rm \" + process0_path + \"log/*.log\") # 删除日志文件\n",
    "        os.system(\"rm \" + data0_path + \"Process::{0..45}.csv\") # 删除中间文件\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1_Process: 计算emit_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据模板文件，多进程操作\n",
    "with open(process1_path + \"1_template.txt\") as f:\n",
    "    template = f.read()\n",
    "for i in range(46):\n",
    "    with open(process1_path + f\"1_Process{i}.txt\", \"w\") as f:\n",
    "        rank = i\n",
    "        file = re.sub(\"X_NUM_X\", str(i), template)\n",
    "        f.write(file)\n",
    "    \n",
    "with open(process1_path+ \"1_run.txt\", \"w\") as ff:\n",
    "    for i in range(46):\n",
    "        ff.write(\"nohup python \" + process1_path+ f\"1_Process{i}.txt >> \" + process1_path + f\"log/P{i}.log 2>&1 &\" + '\\n')\n",
    "\n",
    "os.system(\"sh \" + process1_path + \"1_run.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并各进程结果\n",
    "while True:\n",
    "    filelist  = listdir(data1_path)\n",
    "    if len(filelist) == 46:\n",
    "        dff_1 = pd.read_csv(data1_path +\"Process_0.csv\")\n",
    "        for i in tqdm(range(1, 46), desc=\"reading\"):\n",
    "            dff2_1 = pd.read_csv(data1_path + f\"Process_{i}.csv\")\n",
    "            dff_1 = dff_1 + dff2_1\n",
    "\n",
    "        for i in tqdm(range(406), desc=\"merging\"):\n",
    "            row_sum = sum(dff_1.iloc[i, :])\n",
    "            dff_1.iloc[i, :] = dff_1.iloc[i, :]/row_sum\n",
    "        dff_1.to_csv(data1_path + \"1_all.csv\", index=0)\n",
    "        os.system(\"rm \" + process1_path + \"log/*.log\") # 删除日志文件\n",
    "        os.system(\"rm \" + data1_path + \"Process_{0..45}.csv\") # 删除中间文件\n",
    "\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c65d005f803e204758a0832aa4706f4cea84163cd45d2efe412da3167c3b3a79"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('tf2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
